{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from vae import VariationalAutoencoder\n",
    "from modules import train_epoch, test_epoch, plot_ae_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\"../media/\")\n",
    "# dataset = torchvision.datasets.MNIST(root=\"/home/szaryvip/Downloads\", train=True, download=True, transform=None)\n",
    "# for idx, (img, _) in enumerate(dataset):\n",
    "#     if idx > 200:\n",
    "#         break\n",
    "#     img.save('../media/unlabeled/{:05d}.jpg'.format(idx))\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset.transform = train_transform\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = len(dataset[0][0])\n",
    "d = 128\n",
    "lr = 1e-3 \n",
    "model = VariationalAutoencoder(in_channels, d, device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss = train_epoch(model,device,train_loader,optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "encoding = []\n",
    "with torch.no_grad():\n",
    "    for img, _ in train_loader:\n",
    "        img.to(device)\n",
    "        encoded = model.encoder(img) \n",
    "        encoding.append(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cd48cbad3aa6fd03280f31814d085807f0517d0ae931dd8e68497b6ed68f269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
